{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DOdCFauEVuGp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "# Operating System\n",
        "OS = platform.system()                                                             # returns 'Windows', 'Linux', etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1ybdcnwFsoX"
      },
      "source": [
        "# Libraries Installation Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8yfeaNF4fq"
      },
      "source": [
        "Installation of all required libraries: SDGym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-D7vrLoFs_S",
        "outputId": "0f570d0f-1043-4440-ad24-2e20fb54654f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "os.system('pip install gdown')\n",
        "os.system('pip install sdgym')\n",
        "os.system('pip install pandas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItRx2G5iqCVe"
      },
      "source": [
        "# All Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pCaLrZdtqEyt"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sdv.demo import load_tabular_demo\n",
        "from sdv.tabular import GaussianCopula, CTGAN, CopulaGAN\n",
        "from sdv.evaluation import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWlXh4Sp9Tu"
      },
      "source": [
        "# All Globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6BkBAOfMnJgp"
      },
      "outputs": [],
      "source": [
        "benchmark = False\n",
        "#benchmark = True\n",
        "gaussian_copula_synth_model = False\n",
        "ctgan_synth_model = False\n",
        "copula_gan_synth_model = True\n",
        "#dataset = 'satgpa'\n",
        "dataset = 'acs'\n",
        "model_names = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esg7OV_Er08N"
      },
      "source": [
        "# All Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NwAd3ykNr3mM"
      },
      "outputs": [],
      "source": [
        "start_global_time = timeit.default_timer()\n",
        "pd.set_option('display.max_columns', 500) \n",
        "pd.set_option('display.max_rows', 500) \n",
        "if ctgan_synth_model == True and copula_gan_synth_model == True: # Only one Gan \n",
        "  ctgan_synth_model = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouW2OiOXJ6Ey"
      },
      "source": [
        "# All Functions Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lfElVjvcJ97x"
      },
      "outputs": [],
      "source": [
        "def explore_data(data): \n",
        "  print(\"\\nHead of Data: \\n\", data.head())\n",
        "  print(\"\\nTail of Data: \\n\", data.tail())\n",
        "  print(\"\\nShape of Data: \", data.shape)\n",
        "  print(\"\\nInformation about Data: \\n\")\n",
        "  try: \n",
        "    data.info()\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nTypes of Data attributes: \\n\")\n",
        "  try: \n",
        "    data.dtypes\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nSummary of all numerical fields in the dataset: \\n\")\n",
        "  try: \n",
        "    data.describe(include = [np.number])\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nSummary of all categorical fields in the dataset: \\n\")\n",
        "  try: \n",
        "    data.describe(include = ['O'])\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nLoop Through Each Column and Check for nulls: \\n\")\n",
        "  try: \n",
        "    for i in range(len(data.columns)):\n",
        "        print(data.columns[i] + \": \" + str(data[data.columns[i]].isna().sum()))\n",
        "  except: \n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6RjXgJbqqjp"
      },
      "source": [
        "# Data Download - ACS and SatGPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cRaHeyccqra1"
      },
      "outputs": [],
      "source": [
        "if benchmark == True: \n",
        "  data = load_tabular_demo('student_placements')\n",
        "  n_to_generate = data.shape[0]\n",
        "else: \n",
        "  if dataset is 'satgpa':\n",
        "    if not os.path.exists(\"./satgpa.csv\"):\n",
        "      os.system('gdown --id \"1NNVF1LhBDkW_KKp5_QW8cAiQDFatzWMy\" --output \"./satgpa.csv\"')\n",
        "      data = pd.read_csv('./satgpa.csv')\n",
        "      data = data.drop(['sat_sum'], axis=1)\n",
        "      data.to_csv('satgpa_no_sum.csv', sep=',')\n",
        "      n_to_generate = data.shape[0]\n",
        "  elif dataset is 'acs':\n",
        "    if not os.path.exists(\"./acs_dataset.zip\"):\n",
        "      os.system('gdown --id \"1mKZfDieGBJP-cS-R7_i3zVKVawXThfUc\" --output \"./acs_dataset.zip\"')\n",
        "      if OS == \"Linux\":\n",
        "          os.system('unzip -o -n \"./acs_dataset.zip\" -d \"./\"')      \n",
        "      #data = pd.read_csv('./acs_dataset.csv')\n",
        "      #n_to_generate = data.shape[0]\n",
        "\n",
        "      data = pd.read_csv('./acs_dataset.csv', nrows = 1000)\n",
        "      n_to_generate = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z98uJzgjsIC1"
      },
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6rQLa3QsNr9",
        "outputId": "5f2d5512-bffc-42a7-f827-a9754be7d1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Head of Data: \n",
            "    Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  HISPAN  \\\n",
            "0           0  17-1001  2012   88.0   1   61.0    1   21      6     1       0   \n",
            "1           1  17-1001  2012   61.0   1   85.0    1   21      6     1       0   \n",
            "2           2  17-1001  2012   54.0   1   54.0    1   21      6     1       0   \n",
            "3           3  17-1001  2012  106.0   1   69.0    1   21      6     1       0   \n",
            "4           4  17-1001  2012   31.0   1   56.0    1   21      6     1       0   \n",
            "\n",
            "   CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  HINSCARE  EDUC  \\\n",
            "0        0         3        1         1        1         1         1     7   \n",
            "1        0         4        1         1        1         1         1     2   \n",
            "2        0         3        2         2        1         1         1     7   \n",
            "3        0         3        2         2        2         1         1     7   \n",
            "4        0         3        2         2        2         1         1     6   \n",
            "\n",
            "   EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  AVAILBLE  WRKRECAL  \\\n",
            "0        1        10         2         2       4        3         5         3   \n",
            "1        1        10         2         2       4        3         5         3   \n",
            "2        1        10         2         2       4        3         5         3   \n",
            "3        3        30         1         1       1        1         5         3   \n",
            "4        1        10         2         3       4        3         5         3   \n",
            "\n",
            "   WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  INCEARN  POVERTY  DEPARTS  \\\n",
            "0         3   14000    14000         0         0    14000      118      902   \n",
            "1         3   18000        0         0         0    18000      262      732   \n",
            "2         3   14000    14000         0         0    14000      118      642   \n",
            "3         3    3800     3800         0         0     3800      262        0   \n",
            "4         3   14000    14000         0         0    14000      501        0   \n",
            "\n",
            "   ARRIVES  sim_individual_id  \n",
            "0      909                 12  \n",
            "1      744                 33  \n",
            "2      654                401  \n",
            "3        0                470  \n",
            "4        0                702  \n",
            "\n",
            "Tail of Data: \n",
            "      Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  \\\n",
            "995         995  17-1300  2012   74.0   1   96.0    1   22      6     1   \n",
            "996         996  17-1300  2012  126.0   1  162.0    1   22      6     1   \n",
            "997         997  17-1300  2012   78.0   1  101.0    1   22      6     1   \n",
            "998         998  17-1300  2012  114.0   1  111.0    1   22      6     1   \n",
            "999         999  17-1300  2012   33.0   1   34.0    1   22      6     1   \n",
            "\n",
            "     HISPAN  CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  \\\n",
            "995       0        0         3        2         2        2         1   \n",
            "996       0        0         3        2         2        2         1   \n",
            "997       0        0         3        1         1        1         1   \n",
            "998       0        0         3        1         1        1         1   \n",
            "999       0        0         3        2         2        1         1   \n",
            "\n",
            "     HINSCARE  EDUC  EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  \\\n",
            "995         1     6        1        10         2         2       4        3   \n",
            "996         1    10        2        20         2         1       1        2   \n",
            "997         1     5        1        10         2         2       1        2   \n",
            "998         1     6        3        30         1         1       1        1   \n",
            "999         1     6        1        10         2         3       4        3   \n",
            "\n",
            "     AVAILBLE  WRKRECAL  WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  \\\n",
            "995         5         3         3    7300     7300         0         0   \n",
            "996         4         3         1       0        0         0         0   \n",
            "997         4         3         3    6800     6800         0         0   \n",
            "998         4         3         3     200      200         0         0   \n",
            "999         5         3         3   16000    16000         0         0   \n",
            "\n",
            "     INCEARN  POVERTY  DEPARTS  ARRIVES  sim_individual_id  \n",
            "995     7300      101      732      809              58149  \n",
            "996        0      363        0        0              58161  \n",
            "997     6800      149     1035     1049              58342  \n",
            "998      200       16        0        0              58495  \n",
            "999    16000      135      502      524              58611  \n",
            "\n",
            "Shape of Data:  (1000, 37)\n",
            "\n",
            "Information about Data: \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 37 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Unnamed: 0         1000 non-null   int64  \n",
            " 1   PUMA               1000 non-null   object \n",
            " 2   YEAR               1000 non-null   int64  \n",
            " 3   HHWT               1000 non-null   float64\n",
            " 4   GQ                 1000 non-null   int64  \n",
            " 5   PERWT              1000 non-null   float64\n",
            " 6   SEX                1000 non-null   int64  \n",
            " 7   AGE                1000 non-null   int64  \n",
            " 8   MARST              1000 non-null   int64  \n",
            " 9   RACE               1000 non-null   int64  \n",
            " 10  HISPAN             1000 non-null   int64  \n",
            " 11  CITIZEN            1000 non-null   int64  \n",
            " 12  SPEAKENG           1000 non-null   int64  \n",
            " 13  HCOVANY            1000 non-null   int64  \n",
            " 14  HCOVPRIV           1000 non-null   int64  \n",
            " 15  HINSEMP            1000 non-null   int64  \n",
            " 16  HINSCAID           1000 non-null   int64  \n",
            " 17  HINSCARE           1000 non-null   int64  \n",
            " 18  EDUC               1000 non-null   int64  \n",
            " 19  EMPSTAT            1000 non-null   int64  \n",
            " 20  EMPSTATD           1000 non-null   int64  \n",
            " 21  LABFORCE           1000 non-null   int64  \n",
            " 22  WRKLSTWK           1000 non-null   int64  \n",
            " 23  ABSENT             1000 non-null   int64  \n",
            " 24  LOOKING            1000 non-null   int64  \n",
            " 25  AVAILBLE           1000 non-null   int64  \n",
            " 26  WRKRECAL           1000 non-null   int64  \n",
            " 27  WORKEDYR           1000 non-null   int64  \n",
            " 28  INCTOT             1000 non-null   int64  \n",
            " 29  INCWAGE            1000 non-null   int64  \n",
            " 30  INCWELFR           1000 non-null   int64  \n",
            " 31  INCINVST           1000 non-null   int64  \n",
            " 32  INCEARN            1000 non-null   int64  \n",
            " 33  POVERTY            1000 non-null   int64  \n",
            " 34  DEPARTS            1000 non-null   int64  \n",
            " 35  ARRIVES            1000 non-null   int64  \n",
            " 36  sim_individual_id  1000 non-null   int64  \n",
            "dtypes: float64(2), int64(34), object(1)\n",
            "memory usage: 289.2+ KB\n",
            "\n",
            "Types of Data attributes: \n",
            "\n",
            "\n",
            "Summary of all numerical fields in the dataset: \n",
            "\n",
            "\n",
            "Summary of all categorical fields in the dataset: \n",
            "\n",
            "\n",
            "Loop Through Each Column and Check for nulls: \n",
            "\n",
            "Unnamed: 0: 0\n",
            "PUMA: 0\n",
            "YEAR: 0\n",
            "HHWT: 0\n",
            "GQ: 0\n",
            "PERWT: 0\n",
            "SEX: 0\n",
            "AGE: 0\n",
            "MARST: 0\n",
            "RACE: 0\n",
            "HISPAN: 0\n",
            "CITIZEN: 0\n",
            "SPEAKENG: 0\n",
            "HCOVANY: 0\n",
            "HCOVPRIV: 0\n",
            "HINSEMP: 0\n",
            "HINSCAID: 0\n",
            "HINSCARE: 0\n",
            "EDUC: 0\n",
            "EMPSTAT: 0\n",
            "EMPSTATD: 0\n",
            "LABFORCE: 0\n",
            "WRKLSTWK: 0\n",
            "ABSENT: 0\n",
            "LOOKING: 0\n",
            "AVAILBLE: 0\n",
            "WRKRECAL: 0\n",
            "WORKEDYR: 0\n",
            "INCTOT: 0\n",
            "INCWAGE: 0\n",
            "INCWELFR: 0\n",
            "INCINVST: 0\n",
            "INCEARN: 0\n",
            "POVERTY: 0\n",
            "DEPARTS: 0\n",
            "ARRIVES: 0\n",
            "sim_individual_id: 0\n"
          ]
        }
      ],
      "source": [
        "explore_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi31R4QBEz_V"
      },
      "source": [
        "# Synthetic Data Generation via Gaussian Copula Method "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5VaMElMMSya"
      },
      "source": [
        "In mathematical terms, a copula is a distribution over the unit cube [0,1]d which is constructed from a multivariate normal distribution over Rd by using the probability integral transform. Intuitively, a copula is a mathematical function that allows us to describe the joint distribution of multiple random variables by analyzing the dependencies between their marginal distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UakSdALyDDcq"
      },
      "outputs": [],
      "source": [
        "if gaussian_copula_synth_model == True:\n",
        "  model = GaussianCopula()\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_gaussian_copula.pkl')\n",
        "  model.save(model_names[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJjwF_kRHdf"
      },
      "source": [
        "# Synthetic Data Generation via Conditional GAN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivhaUFEiRXeF"
      },
      "source": [
        "Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design TGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. TGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ThtphOVcRSKB"
      },
      "outputs": [],
      "source": [
        "if ctgan_synth_model == True:\n",
        "  model = CTGAN(\n",
        "    epochs=500,\n",
        "    batch_size=100,\n",
        "    generator_dim=(256, 256, 256),\n",
        "    discriminator_dim=(256, 256, 256)\n",
        "  )\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_ctgan.pkl')\n",
        "  model.save(model_names[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data Generation via Copula GAN "
      ],
      "metadata": {
        "id": "Qc1f5o3yXpRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CopulaGAN model is a variation of the CTGAN Model which takes advantage of the CDF based transformation that the GaussianCopulas apply to make the underlying CTGAN model task of learning the data easier.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6VdYznSanO5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if copula_gan_synth_model == True:\n",
        "  model = CopulaGAN(\n",
        "    epochs=500,\n",
        "    batch_size=100,\n",
        "    generator_dim=(256, 256, 256),\n",
        "    discriminator_dim=(256, 256, 256)\n",
        "  )\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_copulagan.pkl')\n",
        "  model.save(model_names[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb-gXMC7mq9f",
        "outputId": "31f8cded-fffe-49c3-a4f5-5ed32d0a5559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:5320: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return c**2 / (c**2 - n**2)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py:2606: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  Lhat = muhat - Shat*mu\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:639: RuntimeWarning: invalid value encountered in sqrt\n",
            "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The number of calls to function has reached maxfev = 600.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:5311: RuntimeWarning: divide by zero encountered in power\n",
            "  return cd2*x**(c-1)\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:43: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  a = (self.min - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:44: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  b = (self.max - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  a = (self.min - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:44: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  b = (self.max - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last five Jacobian evaluations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaartIlNulb"
      },
      "source": [
        "# Model Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_ZCIS-M3oI"
      },
      "outputs": [],
      "source": [
        "model_file = []\n",
        "model_to_load = []\n",
        "if gaussian_copula_synth_model == True:\n",
        "  model_file.append(model_names[0])\n",
        "  model_to_load.append((\"GaussianCopula\", GaussianCopula))\n",
        "if ctgan_synth_model == True:\n",
        "  model_file.append(model_names[-1])\n",
        "  model_to_load.append((\"CTGAN\", CTGAN))\n",
        "elif copula_gan_synth_model == True:\n",
        "  model_file.append(model_names[-1])\n",
        "  model_to_load.append((\"COPULAGAN\", CopulaGAN))\n",
        "\n",
        "loaded_model = []\n",
        "for mf,ml in zip(model_file, model_to_load): \n",
        "  loaded_model.append((ml[0], ml[1].load(mf)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn0T8pLAa1aN"
      },
      "source": [
        "# Synthetic Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSjwsi4zMK2u"
      },
      "outputs": [],
      "source": [
        "synthetic_data = []\n",
        "for lm in loaded_model: \n",
        "  synthetic_data.append((lm[0], lm[1].sample(n_to_generate)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY_hj9EWKRLM"
      },
      "source": [
        "# Synthetic Data Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEzGfEZKIWeV"
      },
      "outputs": [],
      "source": [
        "scored_and_synth_data = []\n",
        "for sd in synthetic_data:\n",
        "  try:\n",
        "    print(\"\\nMethod: \",sd[0])\n",
        "    explore_data(sd[1])\n",
        "    score = evaluate(sd[1], data)\n",
        "    print(\"\\n\\nScore: \", score)\n",
        "    scored_and_synth_data.append((sd[0], sd[1], score))  \n",
        "  except:\n",
        "    print(\"Error\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXRRKM9i4cft"
      },
      "outputs": [],
      "source": [
        "total_time = timeit.default_timer() - start_global_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CticH5Bsg-Y0"
      },
      "outputs": [],
      "source": [
        "for sas in scored_and_synth_data:\n",
        "  sas[1].to_csv(dataset+'_synth_data_generated_by_method_'+sas[0].lower()+'total_time_'+str(round(total_time,2))+'_score_'+str(round(sas[2],3))+'.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0DMKRkeqSJZ"
      },
      "outputs": [],
      "source": [
        "print(\"Global Exectution Time: \", total_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "gan_sdgym_istat_synt_challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}